#!/usr/bin/env python3
"""
Enhanced RT module with automatic audio device detection and switching.
Automatically selects the best available microphone based on priority.
"""

import argparse
import sys
import os
import tempfile
import wave
import time

import mlx_whisper
import pyaudio
import numpy as np
import pyperclip
import sounddevice as sd

# Model configuration
MODEL_NAME = os.environ.get(
    "WHISPER_MODEL",
    "mlx-community/whisper-large-v3-turbo"
)

# Audio parameters
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024

# Silence detection parameters
SILENCE_THRESHOLD = 1000
SILENCE_DURATION = 1.5

class SmartAudioDevice:
    """Smart audio device selector with priority-based selection."""

    # Device priority (higher = better)
    DEVICE_PRIORITIES = {
        # External devices (highest priority)
        'usb': 100,           # USB –º–∏–∫—Ä–æ—Ñ–æ–Ω—ã
        'thunderbolt': 95,    # Thunderbolt –∞—É–¥–∏–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã

        # Wireless devices
        'airpods': 80,        # AirPods (—Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
        'bluetooth': 70,      # –î—Ä—É–≥–∏–µ Bluetooth —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

        # Virtual devices
        'blackhole': 60,      # BlackHole –¥–ª—è –∑–∞–ø–∏—Å–∏ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞
        'multi-output': 55,   # Multi-Output Device
        'aggregate': 50,      # Aggregate Device

        # Built-in devices (lowest priority)
        'macbook': 30,        # –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–∏–∫—Ä–æ—Ñ–æ–Ω MacBook
        'built-in': 25,       # –î—Ä—É–≥–∏–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ
        'default': 20         # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    }

    @classmethod
    def detect_device_type(cls, device_name):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –ø–æ –∏–º–µ–Ω–∏."""
        name_lower = device_name.lower()

        # External
        if 'usb' in name_lower or 'yeti' in name_lower or 'blue' in name_lower:
            return 'usb'
        if 'thunderbolt' in name_lower or 'apollo' in name_lower:
            return 'thunderbolt'

        # Wireless
        if 'airpods' in name_lower:
            return 'airpods'
        if 'bluetooth' in name_lower or 'bt' in name_lower:
            return 'bluetooth'

        # Virtual
        if 'blackhole' in name_lower:
            return 'blackhole'
        if 'multi-output' in name_lower:
            return 'multi-output'
        if 'aggregate' in name_lower:
            return 'aggregate'

        # Built-in
        if 'macbook' in name_lower or 'internal' in name_lower:
            return 'macbook'
        if 'built-in' in name_lower:
            return 'built-in'

        return 'default'

    @classmethod
    def get_best_device(cls):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª—É—á—à–µ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–≤–æ–¥–∞."""
        p = pyaudio.PyAudio()
        devices = []

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤–≤–æ–¥–∞
        for i in range(p.get_device_count()):
            try:
                info = p.get_device_info_by_index(i)
                if info['maxInputChannels'] > 0:
                    device_type = cls.detect_device_type(info['name'])
                    priority = cls.DEVICE_PRIORITIES.get(device_type, 0)
                    devices.append({
                        'index': i,
                        'name': info['name'],
                        'type': device_type,
                        'priority': priority,
                        'channels': info['maxInputChannels']
                    })
            except Exception:
                continue

        p.terminate()

        if not devices:
            return None

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–∞–Ω–∞–ª–æ–≤ –∫–∞–∫ –≤—Ç–æ—Ä–∏—á–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π)
        devices.sort(key=lambda x: (x['priority'], x['channels']), reverse=True)

        best_device = devices[0]

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞
        print(f"üé§ –í—ã–±—Ä–∞–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {best_device['name']} ({best_device['type']})",
              file=sys.stderr)

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö
        if len(devices) > 1:
            print(f"   –î–æ—Å—Ç—É–ø–Ω—ã —Ç–∞–∫–∂–µ: {', '.join(d['name'] for d in devices[1:3])}",
                  file=sys.stderr)

        return best_device['index']

    @classmethod
    def monitor_device_changes(cls, callback=None):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ (–¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)."""
        # –ú–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ polling –∏–ª–∏ system events
        pass

def record_until_silence(device_index=None):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞."""

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
    if device_index is None:
        device_index = SmartAudioDevice.get_best_device()

    audio = pyaudio.PyAudio()

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ—Ç–æ–∫–∞
    stream_kwargs = {
        'format': FORMAT,
        'channels': CHANNELS,
        'rate': RATE,
        'input': True,
        'frames_per_buffer': CHUNK
    }

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –µ—Å–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
    if device_index is not None:
        stream_kwargs['input_device_index'] = device_index

    try:
        stream = audio.open(**stream_kwargs)
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞, –∏—Å–ø–æ–ª—å–∑—É—é —Å–∏—Å—Ç–µ–º–Ω–æ–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é",
              file=sys.stderr)
        # Fallback –Ω–∞ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        stream_kwargs.pop('input_device_index', None)
        stream = audio.open(**stream_kwargs)

    print("üéô  –û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ—á–∏...", file=sys.stderr)

    frames = []
    silent_chunks = 0
    has_sound = False
    is_speaking = False

    # –ó–≤—É–∫–æ–≤–æ–π —Å–∏–≥–Ω–∞–ª –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏
    os.system("play -n synth 0.1 sine 1000 2>/dev/null &")

    try:
        while True:
            data = stream.read(CHUNK, exception_on_overflow=False)
            audio_chunk = np.frombuffer(data, dtype=np.int16)

            volume = np.abs(audio_chunk).mean()

            if volume > SILENCE_THRESHOLD:
                silent_chunks = 0
                if not is_speaking:
                    is_speaking = True
                    has_sound = True
                    print("üî¥ –ó–∞–ø–∏—Å—å...", file=sys.stderr)
                frames.append(data)
            else:
                if is_speaking:
                    frames.append(data)
                    silent_chunks += 1
                    if silent_chunks > int(SILENCE_DURATION * RATE / CHUNK):
                        print("‚è∏  –ü–∞—É–∑–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞", file=sys.stderr)
                        break

    except KeyboardInterrupt:
        pass

    finally:
        stream.stop_stream()
        stream.close()
        audio.terminate()

    if not has_sound:
        return np.array([])

    # –ó–≤—É–∫–æ–≤–æ–π —Å–∏–≥–Ω–∞–ª –∫–æ–Ω—Ü–∞ –∑–∞–ø–∏—Å–∏
    os.system("play -n synth 0.1 sine 800 2>/dev/null &")

    audio_data = b''.join(frames)
    audio_array = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0

    return audio_array

def transcribe_audio(audio_array, language=None):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é MLX Whisper."""
    if len(audio_array) == 0:
        return ""

    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
        wav_file = wave.open(tmp_file.name, 'wb')
        wav_file.setnchannels(CHANNELS)
        wav_file.setsampwidth(2)
        wav_file.setframerate(RATE)
        wav_file.writeframes((audio_array * 32768).astype(np.int16).tobytes())
        wav_file.close()

        options = {}
        if language:
            options['language'] = language

        result = mlx_whisper.transcribe(
            tmp_file.name,
            path_or_hf_repo=MODEL_NAME,
            verbose=False,
            **options
        )

        os.unlink(tmp_file.name)

    return result.get("text", "").strip()

def list_devices():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏."""
    print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:\n")
    print(f"{'‚Ññ':<4} {'–ò–º—è':<40} {'–¢–∏–ø':<15} {'–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç':<10} {'–ö–∞–Ω–∞–ª—ã'}")
    print("-" * 80)

    p = pyaudio.PyAudio()
    devices = []

    for i in range(p.get_device_count()):
        try:
            info = p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                device_type = SmartAudioDevice.detect_device_type(info['name'])
                priority = SmartAudioDevice.DEVICE_PRIORITIES.get(device_type, 0)
                devices.append({
                    'index': i,
                    'name': info['name'][:39],
                    'type': device_type,
                    'priority': priority,
                    'channels': info['maxInputChannels']
                })
        except Exception:
            continue

    devices.sort(key=lambda x: x['priority'], reverse=True)

    for d in devices:
        star = "‚≠ê" if d == devices[0] else "  "
        print(f"{star}{d['index']:<2} {d['name']:<40} {d['type']:<15} {d['priority']:<10} {d['channels']}")

    p.terminate()

    print("\n‚≠ê = –ë—É–¥–µ—Ç –≤—ã–±—Ä–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
    print("\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: ./mlxw --device <–Ω–æ–º–µ—Ä> –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞")

def main():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–æ–¥–∏–Ω —Ä–∞–∑)."""
    print(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {MODEL_NAME}...", file=sys.stderr)

    try:
        # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –ª–∞—Ç–µ–Ω—Ü–∏–∏
        _ = mlx_whisper.load_model(path_or_hf_repo=MODEL_NAME)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}", file=sys.stderr)
        sys.exit(1)

    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!", file=sys.stderr)

def run_single(language=None, device_index=None):
    """–†–µ–∂–∏–º –æ–¥–Ω–æ–π —Ñ—Ä–∞–∑—ã —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞."""
    audio = record_until_silence(device_index)

    if len(audio) == 0:
        print("‚ùå –†–µ—á—å –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞", file=sys.stderr)
        return

    print("üîÑ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...", file=sys.stderr)
    text = transcribe_audio(audio, language)

    if text:
        pyperclip.copy(text)
        print(text)
        print("‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞!", file=sys.stderr)
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å", file=sys.stderr)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Real-time STT with smart device selection")
    parser.add_argument("--single", action="store_true", help="–û–¥–Ω–∞ —Ñ—Ä–∞–∑–∞ –∏ –≤—ã—Ö–æ–¥")
    parser.add_argument("--lang", type=str, help="–Ø–∑—ã–∫ (ru/en/auto)")
    parser.add_argument("--device", type=int, help="–ò–Ω–¥–µ–∫—Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (—Å–º. --list-devices)")
    parser.add_argument("--list-devices", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞")

    args = parser.parse_args()

    if args.list_devices:
        list_devices()
        sys.exit(0)

    main()

    if args.single:
        run_single(args.lang, args.device)
    else:
        # –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π —Ä–µ–∂–∏–º
        print("üì¢ –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π —Ä–µ–∂–∏–º. –°–∫–∞–∂–∏—Ç–µ '–≤—ã—Ö–æ–¥' –∏–ª–∏ 'exit' –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.",
              file=sys.stderr)
        while True:
            audio = record_until_silence(args.device)
            if len(audio) > 0:
                text = transcribe_audio(audio, args.lang)
                if text:
                    print(f"üìù {text}")
                    if "–≤—ã—Ö–æ–¥" in text.lower() or "exit" in text.lower():
                        break